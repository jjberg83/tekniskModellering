{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939c2ffd",
   "metadata": {},
   "source": [
    "## How a single and multilayer perceptron computation works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ee62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, the main issues to learn \n",
    "#   a) compuation at each perceptrion is performed, by implementing the mathematical model discussed in the class\n",
    "#   b) computration at each perception is performed by the python implemented numpy\n",
    "# From the two example, we learn how both computation results the same and also how the numpy is simple coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d30ee6",
   "metadata": {},
   "source": [
    "### Example 1a: Computation at each perceptrion is performed, by implementing the mathematical model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9bcd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.93\n",
      "Sigmoid: 0.9999999998899405\n",
      "LeakyRelu: 22.93\n",
      "Relu: 22.93\n",
      "Tanh: 1.0\n",
      "Swish: 22.929999997476337\n"
     ]
    }
   ],
   "source": [
    "#Example 1: Compuation at each perceptrion is performed, by implementing the mathematical model discussed in the class\n",
    "#Neural Networks from Scratch - P.2 Coding a Single Perceptrion Layer\n",
    "# Four input signals will be weighted with four weights. A single bias will be added\n",
    "\n",
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "#Input-weight-bias given in list\n",
    "input = [2.1, 3.2, 2.6,1.2]\n",
    "weight = [1.5, 2.9, 2.3, 2.1]\n",
    "bias = 2\n",
    "\n",
    "# Compute linear combination of the weighted sum of the input added with the bias\n",
    "\n",
    "output = input[0]*weight[0]+input[1]*weight[1]+input[2]*weight[2]+input[3]*weight[3]+bias\n",
    "print(output)\n",
    "\n",
    "# The linear combined sum will pass through the activation function to convert to output signal.\n",
    "# For this, we need to define an activation fuction, example sigmoid, relue and tanha\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "print('Sigmoid:',sigmoid(output))\n",
    "\n",
    "\n",
    "def LeakyRelu(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else :\n",
    "        return 0.01*x\n",
    "print('LeakyRelu:',LeakyRelu(output))\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    return max(0,x)\n",
    "print('Relu:',Relu(output))\n",
    "\n",
    "def Tanh(x):\n",
    "      return  (np.exp(x)- np.exp(-x))/( np.exp(x)+ np.exp(-x))\n",
    "print('Tanh:',Tanh(output))\n",
    "\n",
    "def Swish(x):\n",
    "      beta =1\n",
    "      return  x/(1+np.exp(-beta*x))\n",
    "print('Swish:',Swish(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c9f0a",
   "metadata": {},
   "source": [
    "### Example 1b: Multilayer Perceptrion computation with numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4486e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.93\n",
      "Sigmoid: 0.9999999998899405\n",
      "LeakyRelu: 22.93\n",
      "Relu: 22.93\n",
      "Tanh: 1.0\n",
      "Swish: 22.929999997476337\n"
     ]
    }
   ],
   "source": [
    "# Example 1a: Application numpy for single Perceptron\n",
    "import numpy as np\n",
    "\n",
    "input = [2.1, 3.2, 2.6,1.2]\n",
    "weight = [1.5, 2.9, 2.3, 2.1]\n",
    "bias = 2\n",
    "\n",
    "output1 = np.dot(input,weight)+bias\n",
    "output = np.sum(output1)\n",
    "print(output1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "print('Sigmoid:',sigmoid(output))\n",
    "\n",
    "def LeakyRelu(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else :\n",
    "        return 0.01*x\n",
    "print('LeakyRelu:',LeakyRelu(output))\n",
    "\n",
    "def Relu(x):\n",
    "    return max(0,x)\n",
    "print('Relu:',Relu(output))\n",
    "\n",
    "def Tanh(x):\n",
    "      return  (np.exp(x)- np.exp(-x))/( np.exp(x)+ np.exp(-x))\n",
    "print('Tanh:',Tanh(output))\n",
    "\n",
    "def Swish(x):\n",
    "      beta =1\n",
    "      return  x/(1+np.exp(-beta*x))\n",
    "print('Swish:',Swish(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361cdd11",
   "metadata": {},
   "source": [
    "### Example 2a: Multilayer Perceptrion by implimenting the mathematical perceptrion model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8afb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output før summering: [17.45, 30.27, 38.03]\n",
      "Sigmoid: 0.9999999736025924\n",
      "Sigmoid: 0.9999999999999285\n",
      "Sigmoid: 1.0\n",
      "Relu: 17.45\n",
      "Relu: 30.27\n",
      "Relu: 38.03\n",
      "LeakyRelu: 17.45\n",
      "LeakyRelu: 30.27\n",
      "LeakyRelu: 38.03\n",
      "Tanh: 0.9999999999999984\n",
      "Tanh: 1.0\n",
      "Tanh: 1.0\n",
      "Swish: 17.449999539365237\n",
      "Swish: 30.269999999997836\n",
      "Swish: 38.03\n"
     ]
    }
   ],
   "source": [
    "# Example 2a: Multilayer Perceptrion\n",
    "# Four Input, and Three Hiden layers with four nodes and three bias\n",
    "import numpy as np\n",
    "input = [2.1, 3.2, 2.6,1.2]\n",
    "weight1 = [2.7, 1.9, 1.3, 1.1]\n",
    "weight2 = [2.5, 3.9, 2.9, 2.5]\n",
    "weight3 = [2.5, 3.9, 4.3, 5.1]\n",
    "\n",
    "bias1 = 1\n",
    "bias2 = 2\n",
    "bias3 = 3\n",
    "\n",
    "output = [input[0]*weight1[0]+input[1]*weight1[1]+input[2]*weight1[2]+input[3]*weight1[3]+bias1,\n",
    "          input[0]*weight2[0]+input[1]*weight2[1]+input[2]*weight2[2]+input[3]*weight2[3]+bias2,\n",
    "          input[0]*weight3[0]+input[1]*weight3[1]+input[2]*weight3[2]+input[3]*weight3[3]+bias3]\n",
    "\n",
    "print(f'Output før summering: {output}') # Denne la jeg til selv\n",
    "# output= np.sum(output1) # Aktiverte denne og den under selv\n",
    "# print(f'Output etter summering: {output}')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "for z in output:\n",
    "    print('Sigmoid:',sigmoid(z))\n",
    "\n",
    "# print('Sigmoid:',sigmoid(output)) # Aktiverte denne selv\n",
    "\n",
    "def Relu(x):\n",
    "    return max(0,x)\n",
    "for z in output:\n",
    "    print('Relu:',Relu(z))\n",
    "\n",
    "def LeakyRelu(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else :\n",
    "        return 0.01*x\n",
    "for z in output:\n",
    "    print('LeakyRelu:', LeakyRelu(z))\n",
    "\n",
    "def Tanh(x):\n",
    "      return  (np.exp(x)- np.exp(-x))/( np.exp(x)+ np.exp(-x))\n",
    "for z in output:\n",
    "    print('Tanh:',Tanh(z))\n",
    "\n",
    "def Swish(x):\n",
    "      beta =1\n",
    "      return  x/(1+np.exp(-beta*x))\n",
    "for z in output:\n",
    "    print('Swish:',Swish(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b14ae",
   "metadata": {},
   "source": [
    "### Example 2b: Multilayer Perceptrion computation with numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7bc6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid: 0.9999999736025924\n",
      "Sigmoid: 0.9999999999999285\n",
      "Sigmoid: 1.0\n",
      "Relu: 17.45\n",
      "Relu: 30.27\n",
      "Relu: 38.03\n",
      "LeakyRelu: 17.45\n",
      "LeakyRelu: 30.27\n",
      "LeakyRelu: 38.03\n",
      "Tanh: 0.9999999999999984\n",
      "Tanh: 1.0\n",
      "Tanh: 1.0\n",
      "Swish: 17.449999539365237\n",
      "Swish: 30.269999999997836\n",
      "Swish: 38.03\n"
     ]
    }
   ],
   "source": [
    "# Example 2b: Multilayer Perceptrion computation with numpy\n",
    "import numpy as np\n",
    "\n",
    "inputs = [2.1, 3.2, 2.6,1.2]\n",
    "\n",
    "# The weights are in list of lists\n",
    "weights = [[2.7, 1.9, 1.3, 1.1],\n",
    "         [2.5, 3.9, 2.9, 2.5],\n",
    "         [2.5, 3.9, 4.3, 5.1]]\n",
    "\n",
    "biases = [1,2,3]\n",
    "\n",
    "output = np.dot(weights,inputs)+biases\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "for z in output:\n",
    "    print('Sigmoid:',sigmoid(z))\n",
    "\n",
    "#print('Sigmoid:',sigmoid(output))\n",
    "\n",
    "def Relu(x):\n",
    "    return max(0,x)\n",
    "for z in output:\n",
    "    print('Relu:',Relu(z))\n",
    "\n",
    "def LeakyRelu(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else :\n",
    "        return 0.01*x\n",
    "for z in output:\n",
    "    print('LeakyRelu:', LeakyRelu(z))\n",
    "\n",
    "def Tanh(x):\n",
    "      return  (np.exp(x)- np.exp(-x))/( np.exp(x)+ np.exp(-x))\n",
    "for z in output:\n",
    "    print('Tanh:',Tanh(z))\n",
    "\n",
    "def Swish(x):\n",
    "      beta =1\n",
    "      return  x/(1+np.exp(-beta*x))\n",
    "for z in output:\n",
    "    print('Swish:',Swish(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9532c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ef6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
